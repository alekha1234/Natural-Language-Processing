{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e997aa38-c03a-435a-ba45-ce20b049c7bd",
   "metadata": {},
   "source": [
    "## Basic Requirments\n",
    "\n",
    "- Regular Expression Module\n",
    "-  Corpus\n",
    "-  Sentence\n",
    "-  Tokenization\n",
    "-  Stopword removal\n",
    "-  Stemming\n",
    "-  Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de610ae4-8c99-443c-a8e3-3074ec8ccca8",
   "metadata": {},
   "source": [
    "## Text to Vector\n",
    "\n",
    "- One Hot Encoding\n",
    "- Bag of Words (BoW)\n",
    "- Term Frequency and Inverse Document Frequency (TF-IDF)\n",
    "- Word embeddings, GloVe ,FastText\n",
    "- n-gram , Bi-gram\n",
    "- Word2Vec\n",
    "- BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98524b47-229f-4e47-8216-a6a72803e453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9481b75f-4f1c-401c-a85c-8c2bf3fca074",
   "metadata": {},
   "source": [
    "# What is NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7dbae-7b63-4ac1-94c4-3e00663c6352",
   "metadata": {},
   "source": [
    "NLP stands for Natural Language Processing. It is the branch of Artificial Intelligence that gives the ability to machine to understand and process human languages. Human languages can be in the form of text or audio format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e1ffb87-78af-4248-8b37-a630f5f56792",
   "metadata": {},
   "source": [
    "Data Acquisition\n",
    "Text Cleaning\n",
    "Text Preprocessing\n",
    "Feature Engineering\n",
    "Model Building\n",
    "Evaluation\n",
    "Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd0d1b-3b11-442d-9832-11b02c804c97",
   "metadata": {},
   "source": [
    "### Step 2 : Text Cleaning:\n",
    "\n",
    "- Unicode Normalization - for handling symbols, emojis, graphic characters, or special characters \n",
    "- Regex or Regular Expression - for pattern matching and manipulation of strings.\n",
    "- Spelling corrections - identifying and correcting misspelled words in text to improve accuracy and readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039920e0-f0b1-4114-9583-d79e85374e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caf√©  is great I love programming in Python  Coding\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "my_text = \"Caf√© üòä is great! I love programming in Python ‚ù§Ô∏èüíª #Coding\"\n",
    "#normalized_text = unicodedata.normalize('NFC', my_text)\n",
    "print(re.sub(r'[^\\w\\s]', '', my_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42a4cd4-bc53-4f87-831e-d2f4f8133630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error words : ['I', 'havv', 'a', 'bab']\n",
      "Corrected words are :\n",
      "{'I'}\n",
      "{'have'}\n",
      "{'a'}\n",
      "{'kab', 'baba', 'abb', 'babe', 'cab', 'jab', 'gab', 'bay', 'bar', 'tab', 'bat', 'nab', 'dab', 'bad', 'blab', 'baby', 'barb', 'fab', 'lab', 'bub', 'ban', 'bag', 'bap', 'bib', 'bob', 'bah', 'baa'}\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyspellchecker\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "text = \"I havv a bab\"\n",
    "words = text.split()\n",
    "print(f\"Error words : {words}\")\n",
    "print(\"Corrected words are :\")\n",
    "for word in words:\n",
    "    print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89f7ad-3f47-4e30-bd1b-1b1a19570daa",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256df22f-4066-4f25-affb-e20d9f338839",
   "metadata": {},
   "source": [
    "\n",
    "1. **Lowercasing**: Converting all characters in a text to lowercase to ensure uniformity.\n",
    "  \n",
    "2. **Removing Punctuation**: Eliminating punctuation marks from text to focus on the words.\n",
    "\n",
    "3. **Tokenization**: Splitting text into individual words or tokens for analysis.\n",
    "\n",
    "4. **Removing Stop Words**: Filtering out common words that carry little meaning in analysis.\n",
    "\n",
    "5. **Lemmatization**: Reducing words to their base or dictionary form, preserving meaning.\n",
    "\n",
    "6. **Stemming**: Cutting words down to their root form, which may not always be a valid word.\n",
    "\n",
    "7. **Handling Numbers**: Convert to text or remove numeric values from text if they do not contribute to the analysis.(num2words)\n",
    "\n",
    "8. **Handling Negations / contractions**: Retaining or modifying negations to preserve sentiment in analysis.(contractions library)\n",
    "\n",
    "9. **Removing Extra Whitespace**: Trimming and normalizing spaces between words for clean formatting.\n",
    "\n",
    "10. **Correcting Misspellings**: Using tools to fix common spelling errors in text using 'pyspellchecker', 'TextBlob', or 'Hunspell' ,'symspellpy / SymSpell'.\n",
    "\n",
    "11. **Removing URLs and Email Addresses**: Eliminating web links and email addresses that are irrelevant to the analysis using modules like \"re\"\n",
    "\n",
    "12. **Removing Non-English Words**: Removing the word which not english word.\n",
    "\n",
    "13. **Encoding Handling / Special Cheracter**: Removing or converting special characters that do not contribute meaningfully (unicode handling).\n",
    "\n",
    "14. **Unicode Normalization**: Transforming text to a standard form to ensure consistent representation of characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab53834-4336-4ec8-826a-b80f8c033c54",
   "metadata": {},
   "source": [
    "## Step 4 : Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a867a-6f5e-4e51-9b75-1c4b75f7f548",
   "metadata": {},
   "source": [
    "- Converting text data into numeric vector representation is known as Text Representation or Text Vectorization.\n",
    "\n",
    "- Classical or Traditional Approach:\n",
    "\n",
    "            - One Hot Encoding\n",
    "            - TF-IDF (Term Frequency ‚Äì Inverse Document Frequency)\n",
    "            - Bag of Word(Bow)\n",
    "\n",
    "- Neural Approach (Word embedding):\n",
    "\n",
    "            - CBOW (Continuous Bag of Words)\n",
    "            - SkipGram\n",
    "            - N-Grams\n",
    "\n",
    "- Pre-Trained Word Embeddings:\n",
    "\n",
    "            - Word2vec - google\n",
    "            - GloV - standford\n",
    "            - fasttext / gensim - facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778235e-ee4f-4531-b9fa-336439cb662e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
